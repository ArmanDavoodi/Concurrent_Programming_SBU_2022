#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <omp.h>

using namespace std;

#define USE_CUDA true // if true uses cuda else serial implementation is used
#define TILED true // if true tiledMatrixMultiplicationKernel is used else simpleMatrixMultiplicationKernel is used
//#define DEBUG // if defined the matrices are printed after the calculation.

constexpr int RUN_COUNT = 10; // number of runs
constexpr int TILE_WIDTH = 16; // same as Block width/height
const char path[300] = "test4096"; // input file path

int N; // size of matrices => A(N x N) . B(N x N) = C(N x N)
double elapsed_t = 0.0;

void loadMatrices(int*& a, int*& b, int*& c); // reads matrices from file generated by matrixGenerator.cpp
void printMatrices(int* a, int* b, int* c);

// computes dot product of A and B and stores the result in C
void sequentialMult(const int *a, const int *b, int *c);
cudaError_t cudaMatrixMultiplication(const int *h_A, const int *h_B, int *h_C);

__global__ void simpleMatrixMultiplicationKernel(const int *a, const int *b, int *c, int N)
{
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int column = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < N && column < N)
    {
        int tempSum = 0;

        // each thread computes one element of the result matrix
        for (int i = 0; i < N; ++i)
            tempSum += a[row * N + i] * b[i * N + column];
        c[row * N + column] = tempSum;
    }
}

__global__ void tiledMatrixMultiplicationKernel(const int* a, const int* b, int* c, int N)
{
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int column = blockIdx.x * blockDim.x + threadIdx.x;

    __shared__ int aTile[TILE_WIDTH][TILE_WIDTH];
    __shared__ int bTile[TILE_WIDTH][TILE_WIDTH];

    int tempSum = 0, numOfTiles = ceil((double)N / (double)TILE_WIDTH);

    for (int i = 0; i < numOfTiles; ++i)
    {
        if (row < N && i * TILE_WIDTH + threadIdx.x < N)
            aTile[threadIdx.y][threadIdx.x] = a[row * N + i * TILE_WIDTH + threadIdx.x];
        else
            aTile[threadIdx.y][threadIdx.x] = 0;
        if (column < N && i * TILE_WIDTH + threadIdx.y < N)
            bTile[threadIdx.y][threadIdx.x] = b[(i * TILE_WIDTH + threadIdx.y) * N + column];
        else
            bTile[threadIdx.y][threadIdx.x] = 0;

        __syncthreads();

        for (int j = 0; j < TILE_WIDTH; ++j)
            tempSum += aTile[threadIdx.y][j] * bTile[j][threadIdx.x];
        __syncthreads();
    }

    if (row < N && column < N)
        c[row * N + column] = tempSum;
}

int main()
{
    int* a = NULL;
    int* b = NULL;
    int* c = NULL;

    printf("loading matrices from file...\n");
    loadMatrices(a, b, c);

    printf("N = %d\n", N);
    #if USE_CUDA == true
        printf("using CUDA ");
        #if TILED == true
            printf("with tiling...\n");
        #else
            printf("without tiling...\n");
        #endif
    #else
        printf("Sequential Algorithm...\n");
    #endif

    for (int i = 0; i < RUN_COUNT; ++i)
    {
        #if USE_CUDA == true
            // compute dot product of matrices in parallel.
            cudaError_t cudaStatus = cudaMatrixMultiplication(a, b, c);
            if (cudaStatus != cudaSuccess) {
                printf("addWithCuda failed!");
                return 1;
            }
        #else
            sequentialMult(a, b, c);
        #endif
    }

    printf("with run count of %d, has average elapsed time of %f seconds\n", RUN_COUNT, elapsed_t/RUN_COUNT);

    #ifdef DEBUG
        printMatrices(a, b, c);
    #endif

    free(a);
    free(b);
    free(c);

    #if USE_CUDA == true
        // cudaDeviceReset must be called before exiting in order for profiling and
        // tracing tools such as Nsight and Visual Profiler to show complete traces.
        cudaError_t cudaStatus = cudaDeviceReset();
        if (cudaStatus != cudaSuccess) {
            printf("cudaDeviceReset failed!");
            return 1;
        }
    #endif

    return 0;
}

void loadMatrices(int*& a, int*& b, int*& c)
{

    FILE* fp = fopen(path, "r");

    fscanf(fp, "%d", &N);
    fscanf(fp, "%d", &N);

    fscanf(fp, "%d", &N);

    a = (int*)malloc(N * N * sizeof(int));
    b = (int*)malloc(N * N * sizeof(int));
    c = (int*)malloc(N * N * sizeof(int));

    if (a == NULL || b == NULL || c == NULL) {
        printf("Memory not allocated.\n");
        exit(0);
    }

    for (int i = 0; i < N * N; ++i)
    {
        fscanf(fp, "%d", a + i);
    }

    for (int i = 0; i < N * N; ++i)
    {
        fscanf(fp, "%d", b + i);
        c[i] = 0;
    }

    fclose(fp);

    printf("\n#### Matrices loaded succesfully! ####\n\n");
}

void printMatrices(int* a, int* b, int* c)
{
    printf("Size = %d\n", N);

    printf("A:\n");
    for (int i = 0; i < N; ++i)
    {
        for (int j = 0; j < N; ++j)
            printf("\t%d ", a[i * N + j]);
        printf("\n");
    }

    printf("\nB:\n");
    for (int i = 0; i < N; ++i)
    {
        for (int j = 0; j < N; ++j)
            printf("\t%d ", b[i * N + j]);
        printf("\n");
    }


    printf("\nC:\n");
    for (int i = 0; i < N; ++i)
    {
        for (int j = 0; j < N; ++j)
            printf("\t%d ", c[i * N + j]);
        printf("\n");
    }

    printf("\n#### Done ####\n\n");
}

void sequentialMult(const int *a, const int *b, int *c)
{
    auto start = omp_get_wtime();
    for (int i = 0; i < N; ++i)
    {
        for (int j = 0; j < N; ++j)
        {
            c[i * N + j] = 0;
            for (int t = 0; t < N; ++t)
            {
                c[i * N + j] += a[i * N + t] * b[t * N + j];
            }
        }
    }
    elapsed_t += omp_get_wtime() - start;
}

cudaError_t cudaMatrixMultiplication(const int *h_A, const int *h_B, int *h_C)
{
    int* d_A = 0;
    int* d_B = 0;
    int* d_C = 0;
    cudaError_t cudaStatus;

    // Allocate GPU buffers for three matrices (two input, one output)    .
    cudaStatus = cudaMalloc((void**)&d_A, N * N * sizeof(int));
    if (cudaStatus != cudaSuccess) {
        printf("cudaMalloc failed!");
        exit(EXIT_FAILURE);
    }

    cudaStatus = cudaMalloc((void**)&d_B, N * N * sizeof(int));
    if (cudaStatus != cudaSuccess) {
        printf("cudaMalloc failed!");
        exit(EXIT_FAILURE);
    }

    cudaStatus = cudaMalloc((void**)&d_C, N * N * sizeof(int));
    if (cudaStatus != cudaSuccess) {
        printf("cudaMalloc failed!");
        exit(EXIT_FAILURE);
    }

    // Copy input matrices from host memory to GPU buffers.
    cudaStatus = cudaMemcpy(d_A, h_A, N * N * sizeof(int), cudaMemcpyHostToDevice);
    if (cudaStatus != cudaSuccess) {
        printf("cudaMemcpy failed!");
        exit(EXIT_FAILURE);
    }

    cudaStatus = cudaMemcpy(d_B, h_B, N * N * sizeof(int), cudaMemcpyHostToDevice);
    if (cudaStatus != cudaSuccess) {
        printf("cudaMemcpy failed!");
        exit(EXIT_FAILURE);
    }

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    dim3 threadsPerBlock(TILE_WIDTH, TILE_WIDTH);
    dim3 blocksPerGrid(ceil((double)N / (double)threadsPerBlock.x), ceil((double)N / (double)threadsPerBlock.y));

    //auto start = omp_get_wtime();
    // Launch a kernel on the GPU
    cudaEventRecord(start, NULL);
    #if TILED == true
        tiledMatrixMultiplicationKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);
    #else
        simpleMatrixMultiplicationKernel<<<blocksPerGrid, threadsPerBlock >>>(d_A, d_B, d_C, N);
    #endif
    cudaEventRecord(stop, NULL);

    // Check for any errors launching the kernel
    cudaStatus = cudaGetLastError();
    if (cudaStatus != cudaSuccess) {
        printf("addKernel launch failed: %s\n", cudaGetErrorString(cudaStatus));
        exit(EXIT_FAILURE);
    }
    cudaEventSynchronize(stop);
    float ms;
    cudaEventElapsedTime(&ms, start, stop);
    elapsed_t += ms / 1000;

    // cudaDeviceSynchronize waits for the kernel to finish, and returns
    // any errors encountered during the launch.
    cudaStatus = cudaDeviceSynchronize();
    if (cudaStatus != cudaSuccess) {
        printf("cudaDeviceSynchronize returned error code %d after launching addKernel!\n", cudaStatus);
        exit(EXIT_FAILURE);
    }

    //elapsed_t += omp_get_wtime() - start;

    // Copy output vector from GPU buffer to host memory.
    cudaStatus = cudaMemcpy(h_C, d_C, N * N * sizeof(int), cudaMemcpyDeviceToHost);
    if (cudaStatus != cudaSuccess) {
        printf("cudaMemcpy failed!");
        exit(EXIT_FAILURE);
    }

    cudaFree(d_C);
    cudaFree(d_A);
    cudaFree(d_B);

    return cudaStatus;
}